
#
# first_url = "https://greyhoundbet.racingpost.com/#result-meeting"
#
# track_id = "69"
# date = "2021-04-02"
# r_time = "08:00"
#
#
# full_url = first_url + "/track_id=" + track_id + "&r_date=" + date + "&r_time=" + r_time
#
# print(full_url)
#
# len_data = 0
#
#
#
# headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 Safari/537.36'}
# page = requests.get(full_url, headers=headers)
#
# print('url crawing: ',full_url)
#
# soup = BeautifulSoup(page.content, 'html.parser')
#
# table = soup.find("div", class_="layout-col2")
#
# all_divs = soup.find_all("div")
#
# soup.find("div").findChildren()
#
# soup.find_all("a", attrs={"class": "container"})
#
#
# for a in soup.find_all('a', href=True):
#     print ("Found the URL:", a['href'])
#     print(a)
#
#
# soup.find_all(href=True)
#
#
#
# soup = BeautifulSoup(page.content, 'html.parser')
# links_with_text = []
# for a in soup.find_all('a', href=True):
#     if a.text:
#         links_with_text.append(a['href'])
#
# soup.find("div", {"class": "resultsList"})
#
#
#
# import urllib.request, urllib.error, urllib.parse
#
#
# response = urllib.request.urlopen(full_url)
# webContent = response.read()
#
#
#
#
# ########################
# full_url = "https://greyhoundbet.racingpost.com/#results-list/r_date=2021-04-03"
#
# headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 Safari/537.36'}
# page = requests.get(full_url, headers=headers)
#
#
# soup = BeautifulSoup(page.content, 'html.parser')
#
#
#
#
# url = "https://greyhoundbet.racingpost.com/#results-list/r_date=2021-04-03/json"
# r = requests.get(url)
# print(r.text)
#
#
#
#
#
#
#
#
#
#
#
#
#
# from webdriver_manager.chrome import ChromeDriverManager
# import time
# from bs4 import BeautifulSoup
# from selenium import webdriver
#
# chromedriver_path= "/Users/.../chromedriver"
#
# #driver = webdriver.Chrome(chromedriver_path)
# driver = webdriver.Chrome(ChromeDriverManager().install())
#
#
# url = "https://greyhoundbet.racingpost.com/#results-list/r_date=2021-04-03"
# driver.get(url)
# time.sleep(3) #if you want to wait 3 seconds for the page to load
# page_source = driver.page_source
#
# soup = bs4.BeautifulSoup(page_source, 'lxml')
#
#
#
#
#
#
#
#
#
#
#
#
#
# ###################################
# import requests
# from bs4 import BeautifulSoup
#
#
#
#
# url = "https://greyhoundstats.co.uk/graded_greyhound_stats.php"
#
# response = requests.get(url, headers=headers)
#
# print(response.text)
#
#
#
#
# soup = BeautifulSoup(response.content, features="lxml")
#
#
#
# links_with_text = []
# for a in soup.find_all('a', href=True):
#     if a.text:
#         links_with_text.append(a['href'])
#
#
#
#
#
# my_all = soup.find_all("span", {"class": "a-size-medium a-color-base a-text-normal"})
#
# print(my_all)


